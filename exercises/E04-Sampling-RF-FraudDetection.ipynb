{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 04\n",
    "\n",
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Fraud Detection Dataset from Microsoft Azure: [data](http://gallery.cortanaintelligence.com/Experiment/8e9fe4e03b8b4c65b9ca947c72b8e463)\n",
    "\n",
    "Fraud detection is one of the earliest industrial applications of data mining and machine learning. Fraud detection is typically handled as a binary classification problem, but the class population is unbalanced because instances of fraud are usually very rare compared to the overall volume of transactions. Moreover, when fraudulent transactions are discovered, the business typically takes measures to block the accounts from transacting to prevent further losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('datasets/fraud_detection.csv.zip', 'r') as z:\n",
    "    f = z.open('15_fraud_detection.csv')\n",
    "    data = pd.io.parsers.read_table(f, index_col=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountAge</th>\n",
       "      <th>digitalItemCount</th>\n",
       "      <th>sumPurchaseCount1Day</th>\n",
       "      <th>sumPurchaseAmount1Day</th>\n",
       "      <th>sumPurchaseAmount30Day</th>\n",
       "      <th>paymentBillingPostalCode - LogOddsForClass_0</th>\n",
       "      <th>accountPostalCode - LogOddsForClass_0</th>\n",
       "      <th>paymentBillingState - LogOddsForClass_0</th>\n",
       "      <th>accountState - LogOddsForClass_0</th>\n",
       "      <th>paymentInstrumentAgeInAccount</th>\n",
       "      <th>ipState - LogOddsForClass_0</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>transactionAmountUSD</th>\n",
       "      <th>ipPostalCode - LogOddsForClass_0</th>\n",
       "      <th>localHour - LogOddsForClass_0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.25</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>1.312186</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>3279.574306</td>\n",
       "      <td>1.218157</td>\n",
       "      <td>599.00</td>\n",
       "      <td>626.164650</td>\n",
       "      <td>1.259543</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>2530.37</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.481838</td>\n",
       "      <td>4.401370</td>\n",
       "      <td>4.500157</td>\n",
       "      <td>61.970139</td>\n",
       "      <td>4.035601</td>\n",
       "      <td>1185.44</td>\n",
       "      <td>1185.440000</td>\n",
       "      <td>3.981118</td>\n",
       "      <td>4.921349</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.056357</td>\n",
       "      <td>3.155226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.314186</td>\n",
       "      <td>32.09</td>\n",
       "      <td>32.090000</td>\n",
       "      <td>5.008490</td>\n",
       "      <td>4.742303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.064533</td>\n",
       "      <td>5.096396</td>\n",
       "      <td>3.331154</td>\n",
       "      <td>3.331239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>133.28</td>\n",
       "      <td>132.729554</td>\n",
       "      <td>1.324925</td>\n",
       "      <td>4.745402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.73</td>\n",
       "      <td>5.412885</td>\n",
       "      <td>0.342945</td>\n",
       "      <td>5.563677</td>\n",
       "      <td>4.086965</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>3.529398</td>\n",
       "      <td>543.66</td>\n",
       "      <td>543.660000</td>\n",
       "      <td>2.693451</td>\n",
       "      <td>4.876771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accountAge  digitalItemCount  sumPurchaseCount1Day  sumPurchaseAmount1Day  \\\n",
       "0        2000                 0                     0                   0.00   \n",
       "1          62                 1                     1                1185.44   \n",
       "2        2000                 0                     0                   0.00   \n",
       "3           1                 1                     0                   0.00   \n",
       "4           1                 1                     0                   0.00   \n",
       "\n",
       "   sumPurchaseAmount30Day  paymentBillingPostalCode - LogOddsForClass_0  \\\n",
       "0                  720.25                                      5.064533   \n",
       "1                 2530.37                                      0.538996   \n",
       "2                    0.00                                      5.064533   \n",
       "3                    0.00                                      5.064533   \n",
       "4                  132.73                                      5.412885   \n",
       "\n",
       "   accountPostalCode - LogOddsForClass_0  \\\n",
       "0                               0.421214   \n",
       "1                               0.481838   \n",
       "2                               5.096396   \n",
       "3                               5.096396   \n",
       "4                               0.342945   \n",
       "\n",
       "   paymentBillingState - LogOddsForClass_0  accountState - LogOddsForClass_0  \\\n",
       "0                                 1.312186                          0.566395   \n",
       "1                                 4.401370                          4.500157   \n",
       "2                                 3.056357                          3.155226   \n",
       "3                                 3.331154                          3.331239   \n",
       "4                                 5.563677                          4.086965   \n",
       "\n",
       "   paymentInstrumentAgeInAccount  ipState - LogOddsForClass_0  \\\n",
       "0                    3279.574306                     1.218157   \n",
       "1                      61.970139                     4.035601   \n",
       "2                       0.000000                     3.314186   \n",
       "3                       0.000000                     3.529398   \n",
       "4                       0.001389                     3.529398   \n",
       "\n",
       "   transactionAmount  transactionAmountUSD  ipPostalCode - LogOddsForClass_0  \\\n",
       "0             599.00            626.164650                          1.259543   \n",
       "1            1185.44           1185.440000                          3.981118   \n",
       "2              32.09             32.090000                          5.008490   \n",
       "3             133.28            132.729554                          1.324925   \n",
       "4             543.66            543.660000                          2.693451   \n",
       "\n",
       "   localHour - LogOddsForClass_0  Label  \n",
       "0                       4.745402      0  \n",
       "1                       4.921349      0  \n",
       "2                       4.742303      0  \n",
       "3                       4.745402      0  \n",
       "4                       4.876771      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138721, 16), 797, 0.0057453449730033666)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.Label.sum(), data.Label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['Label'], axis=1)\n",
    "Y = data['Label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.1\n",
    "\n",
    "Estimate a Logistic Regression\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class_log = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.993973645512\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy',metrics.accuracy_score(y_pred_class_log,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('F1 Score',metrics.f1_score(y_pred_class_log,y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Beta Score (Beta=10) 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('F Beta Score (Beta=10)',metrics.fbeta_score(y_pred_class_log,y_test.values,beta=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy para el modelo es bastante bueno, ya que indica que el 99.4% de los datos están clasificando correctamente en la categoría correspondiente. El F1-Score y F-Beta-Score no pueden ser calculados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.2\n",
    "\n",
    "Under-sample the negative class using random-under-sampling\n",
    "\n",
    "Which is parameter for target_percentage did you choose?\n",
    "How the results change?\n",
    "\n",
    "**Only apply under-sampling to the training set, evaluate using the whole test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UnderSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_0_new =  n_samples_1 / target_percentage - n_samples_1\n",
    "    n_samples_0_new_per = n_samples_0_new / n_samples_0\n",
    "\n",
    "    filter_ = y == 0\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rand_1 = np.random.binomial(n=1, p=n_samples_0_new_per, size=n_samples)\n",
    "    \n",
    "    filter_ = filter_ & rand_1\n",
    "    filter_ = filter_ | (y == 1)\n",
    "    filter_ = filter_.astype(bool)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.1\n",
      "y.shape =  5966 y.mean() =  0.09855849815621857\n",
      "Accuracy 0.993483463568\n",
      "F1 Score 0.0\n",
      "F Beta Score (Beta=10) 0.0\n",
      " \n",
      "Target percentage 0.2\n",
      "y.shape =  3020 y.mean() =  0.1947019867549669\n",
      "Accuracy 0.982238113088\n",
      "F1 Score 0.0609756097561\n",
      "F Beta Score (Beta=10) 0.0449798481373\n",
      " \n",
      "Target percentage 0.3\n",
      "y.shape =  2029 y.mean() =  0.2897979300147856\n",
      "Accuracy 0.974597041608\n",
      "F1 Score 0.049622437972\n",
      "F Beta Score (Beta=10) 0.0322598564068\n",
      " \n",
      "Target percentage 0.4\n",
      "y.shape =  1489 y.mean() =  0.3948959032907992\n",
      "Accuracy 0.919696663879\n",
      "F1 Score 0.037331489803\n",
      "F Beta Score (Beta=10) 0.0203046063237\n",
      " \n",
      "Target percentage 0.5\n",
      "y.shape =  1208 y.mean() =  0.4867549668874172\n",
      "Accuracy 0.520371384908\n",
      "F1 Score 0.0194529592077\n",
      "F Beta Score (Beta=10) 0.00994504415743\n",
      " \n",
      "Target percentage 0.6\n",
      "y.shape =  998 y.mean() =  0.5891783567134269\n",
      "Accuracy 0.378881808483\n",
      "F1 Score 0.017155632614\n",
      "F Beta Score (Beta=10) 0.00874616365017\n",
      " \n",
      "Target percentage 0.7\n",
      "y.shape =  842 y.mean() =  0.6983372921615202\n",
      "Accuracy 0.263025864306\n",
      "F1 Score 0.0147257237578\n",
      "F Beta Score (Beta=10) 0.00749628216891\n",
      " \n",
      "Target percentage 0.8\n",
      "y.shape =  735 y.mean() =  0.8\n",
      "Accuracy 0.150889536057\n",
      "F1 Score 0.0132689987937\n",
      "F Beta Score (Beta=10) 0.00674762603211\n",
      " \n",
      "Target percentage 0.9\n",
      "y.shape =  647 y.mean() =  0.9088098918083463\n",
      "Accuracy 0.0410599463683\n",
      "F1 Score 0.0123541116028\n",
      "F Beta Score (Beta=10) 0.00627739900299\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7,0.8,0.9]:\n",
    "    X_u, y_u = UnderSampling(X_train, y_train, target_percentage, 666)\n",
    "    print('Target percentage', target_percentage)\n",
    "    print('y.shape = ',y_u.shape[0], 'y.mean() = ', y_u.mean())\n",
    "    logreg.fit(X_u, y_u)\n",
    "    y_pred_class_log = logreg.predict(X_test)\n",
    "    print('Accuracy',metrics.accuracy_score(y_pred_class_log,y_test))\n",
    "    print('F1 Score',metrics.f1_score(y_pred_class_log,y_test))\n",
    "    print('F Beta Score (Beta=10)',metrics.fbeta_score(y_pred_class_log,y_test,beta=10))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor para el Target percentage que elegiría es **0.2** ya que maximiza tanto el Accuracy, como el F1 Score y el F Beta Score. Se puede observar como tal que no hay un patrón al aumentar el valor del target percentage, sin embargo hay un punto que maximiza las métricas de evaluación del modelo y tienden a bajar a medida que el valor del target percentage aumenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.3\n",
    "\n",
    "Now using random-over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def OverSampling(X, y, target_percentage=0.5, seed=None):\n",
    "    # Assuming minority class is the positive\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "\n",
    "    n_samples_1_new =  -target_percentage * n_samples_0 / (target_percentage- 1)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    filter_ = np.random.choice(X[y == 1].shape[0], int(n_samples_1_new))\n",
    "    # filter_ is within the positives, change to be of all\n",
    "    filter_ = np.nonzero(y == 1)[0][filter_]\n",
    "    \n",
    "    filter_ = np.concatenate((filter_, np.nonzero(y == 0)[0]), axis=0)\n",
    "    \n",
    "    return X[filter_], y[filter_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[ 41645  75082  12793 ..., 104037 104038 104039] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a0089fd0dc51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOverSampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m666\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_u\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-9b250988f29f>\u001b[0m in \u001b[0;36mOverSampling\u001b[1;34m(X, y, target_percentage, seed)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfilter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2000\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[ 41645  75082  12793 ..., 104037 104038 104039] not in index'"
     ]
    }
   ],
   "source": [
    "    X_u, y_u = OverSampling(X_train, y_train, 0.5, 666)\n",
    "    X_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.1\n",
      "y.shape =  114946 y.mean() =  0.005550405561993047\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ebaea907f3c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Target percentage'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_percentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y.shape = '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_u\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y.mean() = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_u\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_u\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_u\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0my_pred_class_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_class_log\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1216\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7,0.8,0.9]:\n",
    "    X_u, y_u = OverSampling(X_train.values, y_train, target_percentage, 666)\n",
    "    print('Target percentage', target_percentage)\n",
    "    print('y.shape = ',y_u.shape[0], 'y.mean() = ', y_u.mean())\n",
    "    logreg.fit(X_u,y_u)\n",
    "    y_pred_class_log = logreg.predict(X_test)\n",
    "    print('Accuracy', metrics.accuracy_score(y_pred_class_log,y_test))\n",
    "    print('F1 Score',metrics.f1_score(y_pred_class_log,y_test))\n",
    "    print('F Beta Score (Beta=10)',metrics.fbeta_score(y_pred_class_log,y_test,beta=10))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.4*\n",
    "Evaluate the results using SMOTE\n",
    "\n",
    "Which parameters did you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SMOTE(X, y, target_percentage=0.5, k=5, seed=None):\n",
    "    \n",
    "    # New samples\n",
    "    n_samples = y.shape[0]\n",
    "    n_samples_0 = (y == 0).sum()\n",
    "    n_samples_1 = (y == 1).sum()\n",
    "    n_samples_1_new =  int(-target_percentage * n_samples_0 / (target_percentage- 1) - n_samples_1)\n",
    "    \n",
    "    # A matrix to store the synthetic samples\n",
    "    new = np.zeros((n_samples_1_new, X.shape[1]))\n",
    "    \n",
    "    # Create seeds\n",
    "    np.random.seed(seed)\n",
    "    seeds = np.random.randint(1, 1000000, 3)\n",
    "    \n",
    "    # Select examples to use as base\n",
    "    np.random.seed(seeds[0])\n",
    "    sel_ = np.random.choice(y[y==1].shape[0], n_samples_1_new)\n",
    "    \n",
    "    # Define random seeds (2 per example)\n",
    "    np.random.seed(seeds[1])\n",
    "    nn__ = np.random.choice(k, n_samples_1_new)\n",
    "    np.random.seed(seeds[2])\n",
    "    steps = np.random.uniform(size=n_samples_1_new)  \n",
    "\n",
    "    # For each selected examples create one synthetic case\n",
    "    for i, sel in enumerate(sel_):\n",
    "        # Select neighbor\n",
    "        nn_ = nn__[i]\n",
    "        step = steps[i]\n",
    "        # Create new sample\n",
    "        new[i, :] = X[y==1][sel] - step * (X[y==1][sel] - X[y==1][nn_])\n",
    "    \n",
    "    X = np.vstack((X, new))\n",
    "    y = np.append(y, np.ones(n_samples_1_new))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.1 k  10\n",
      "y.shape =  114946 y.mean() =  0.0999947801576\n",
      "Accuracy 0.991522735792\n",
      "F1 Score 0.00675675675676\n",
      "F Beta Score (Beta=10) 0.011336850376\n",
      " \n",
      "Target percentage 0.2 k  10\n",
      "y.shape =  129315 y.mean() =  0.2\n",
      "Accuracy 0.975404400104\n",
      "F1 Score 0.0361581920904\n",
      "F Beta Score (Beta=10) 0.0238316447669\n",
      " \n",
      "Target percentage 0.3 k  10\n",
      "y.shape =  147788 y.mean() =  0.29999729342\n",
      "Accuracy 0.956344972752\n",
      "F1 Score 0.0269922879177\n",
      "F Beta Score (Beta=10) 0.0157217087074\n",
      " \n",
      "Target percentage 0.4 k  10\n",
      "y.shape =  172420 y.mean() =  0.4\n",
      "Accuracy 0.857818402007\n",
      "F1 Score 0.0167497507478\n",
      "F Beta Score (Beta=10) 0.00882263019203\n",
      " \n",
      "Target percentage 0.5 k  10\n",
      "y.shape =  206904 y.mean() =  0.5\n",
      "Accuracy 0.698826446758\n",
      "F1 Score 0.0174960022575\n",
      "F Beta Score (Beta=10) 0.0090108585018\n",
      " \n",
      "Target percentage 0.6 k  10\n",
      "y.shape =  258629 y.mean() =  0.599998453383\n",
      "Accuracy 0.529425333756\n",
      "F1 Score 0.0153252081574\n",
      "F Beta Score (Beta=10) 0.00783706816545\n",
      " \n",
      "Target percentage 0.7 k  10\n",
      "y.shape =  344839 y.mean() =  0.699999130029\n",
      "Accuracy 0.309477812058\n",
      "F1 Score 0.0143233454067\n",
      "F Beta Score (Beta=10) 0.00729541879747\n",
      " \n",
      "Target percentage 0.8 k  10\n",
      "y.shape =  517260 y.mean() =  0.8\n",
      "Accuracy 0.201176436666\n",
      "F1 Score 0.0139521640091\n",
      "F Beta Score (Beta=10) 0.00709811614506\n",
      " \n",
      "Target percentage 0.9 k  10\n",
      "y.shape =  1034520 y.mean() =  0.9\n",
      "Accuracy 0.112251665177\n",
      "F1 Score 0.0128254456842\n",
      "F Beta Score (Beta=10) 0.0065201062971\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for target_percentage in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "        X_u, y_u = SMOTE(X_train.values, y_train, target_percentage, 10, seed=666)\n",
    "        print('Target percentage', target_percentage, 'k ', 10)\n",
    "        print('y.shape = ',y_u.shape[0], 'y.mean() = ', y_u.mean())\n",
    "        logreg.fit(X_u,y_u)\n",
    "        y_pred_class_log = logreg.predict(X_test)\n",
    "        print('Accuracy', metrics.accuracy_score(y_pred_class_log,y_test))\n",
    "        print('F1 Score',metrics.f1_score(y_pred_class_log,y_test))\n",
    "        print('F Beta Score (Beta=10)',metrics.fbeta_score(y_pred_class_log,y_test,beta=10))\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor para el Target percentage que elegiría es **0.2** ya que maximiza tanto el Accuracy, como el F1 Score y el F Beta Score. Se puede observar como tal que no hay un patrón al aumentar el valor del target percentage, sin embargo hay un punto que maximiza las métricas de evaluación del modelo y tienden a bajar a medida que el valor del target percentage aumenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.5\n",
    "\n",
    "Estimate a Logistic Regression, GaussianNB, K-nearest neighbors and a Decision Tree **Classifiers**\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score\n",
    "* F_Beta-Score (Beta=10)\n",
    "\n",
    "Comment about the results\n",
    "\n",
    "Combine the classifiers and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {'lr': LogisticRegression(),\n",
    "          'dt': DecisionTreeClassifier(),\n",
    "          'nb': GaussianNB(),\n",
    "          'nn': KNeighborsClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=666)\n",
    "\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict test for each model\n",
    "y_pred = pd.DataFrame(index=X_test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.076507183297\n",
      "dt 0.105088109965\n",
      "nb 0.137846867531\n",
      "nn 0.0770704339682\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(mean_squared_error(y_pred[model], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr precision 0.0\n",
      "lr recall 0.0\n",
      "lr f1.score 0.0\n",
      "lr fbeta 0.0\n",
      " \n",
      "dt precision 0.137931034483\n",
      "dt recall 0.118644067797\n",
      "dt f1.score 0.127562642369\n",
      "dt fbeta 0.118808553544\n",
      " \n",
      "nb precision 0.0246305418719\n",
      "nb recall 0.0107296137339\n",
      "nb f1.score 0.0149476831091\n",
      "nb fbeta 0.0107899066299\n",
      " \n",
      "nn precision 0.0443349753695\n",
      "nn recall 0.428571428571\n",
      "nn f1.score 0.0803571428571\n",
      "nn fbeta 0.394702561876\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "for model in models.keys():\n",
    "    print(model, 'precision',metrics.precision_score(y_pred[model],y_test))\n",
    "    print(model, 'recall', metrics.recall_score(y_pred[model],y_test))\n",
    "    print(model, 'f1.score',metrics.f1_score(y_pred[model],y_test))\n",
    "    print(model, 'fbeta',metrics.fbeta_score(y_pred[model],y_test,beta=10))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que en cuanto a precisión, el mejor modelo es el árbol de clasificación con 0,13. Sin embargo, el modelo que mejor presenta recall es el modelo KNeighborsClassifier con 0.4285, es decir que este modelo está prediciendo mejor los verdaderos positivos sobre el total de los que fueron clasificados correctamente (falsos negativos y verdaderos positivos). El modelo que mejor que presenta la mezcla entre la presición y el recall, es decir, el f1 score es el modelo de árbol de clasificación con 0.1275. Finalmente, el modelo que mejor tiene un f beta score, es decir, la media armónica ponderada entre el recall y la presición, es el modelo Gaussian Naive Bayes con 0.3947."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta 0.333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred=y_pred.astype(np.int)\n",
    "y_pred.mode(axis=1).values[:,0]\n",
    "print('fbeta',metrics.fbeta_score(y_pred.mode(axis=1).values[:,0],y_test,beta=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que combinando el f beta no mejora, ya que pasa de tener un 0.3947 con un modelo Gaussian Naive Bayes a un 0.3333 con una combinación entre este anterior, una regresión logística, un árbol de clasificación y un k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 04.6\n",
    "\n",
    "Using the under-sampled dataset\n",
    "\n",
    "Evaluate a RandomForestClassifier and compare the results\n",
    "\n",
    "change n_estimators=100, what happened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target percentage 0.2\n",
      "y.shape =  3054 y.mean() =  0.1944990176817289\n",
      "ntree =  100\n",
      "F Beta Score (Beta=10) 0.0710014770582\n",
      " \n",
      "Target percentage 0.2\n",
      "y.shape =  3054 y.mean() =  0.1944990176817289\n",
      "ntree =  200\n",
      "F Beta Score (Beta=10) 0.0734674628106\n",
      " \n",
      "Target percentage 0.2\n",
      "y.shape =  3054 y.mean() =  0.1944990176817289\n",
      "ntree =  500\n",
      "F Beta Score (Beta=10) 0.0735419043227\n",
      " \n",
      "Target percentage 0.4\n",
      "y.shape =  1501 y.mean() =  0.39573617588274485\n",
      "ntree =  100\n",
      "F Beta Score (Beta=10) 0.0299223113789\n",
      " \n",
      "Target percentage 0.4\n",
      "y.shape =  1501 y.mean() =  0.39573617588274485\n",
      "ntree =  200\n",
      "F Beta Score (Beta=10) 0.0295718722621\n",
      " \n",
      "Target percentage 0.4\n",
      "y.shape =  1501 y.mean() =  0.39573617588274485\n",
      "ntree =  500\n",
      "F Beta Score (Beta=10) 0.0292587294494\n",
      " \n",
      "Target percentage 0.6\n",
      "y.shape =  1011 y.mean() =  0.5875370919881305\n",
      "ntree =  100\n",
      "F Beta Score (Beta=10) 0.0140301921278\n",
      " \n",
      "Target percentage 0.6\n",
      "y.shape =  1011 y.mean() =  0.5875370919881305\n",
      "ntree =  200\n",
      "F Beta Score (Beta=10) 0.0139785897549\n",
      " \n",
      "Target percentage 0.6\n",
      "y.shape =  1011 y.mean() =  0.5875370919881305\n",
      "ntree =  500\n",
      "F Beta Score (Beta=10) 0.0140106071961\n",
      " \n",
      "Target percentage 0.8\n",
      "y.shape =  743 y.mean() =  0.7994616419919246\n",
      "ntree =  100\n",
      "F Beta Score (Beta=10) 0.00743082131552\n",
      " \n",
      "Target percentage 0.8\n",
      "y.shape =  743 y.mean() =  0.7994616419919246\n",
      "ntree =  200\n",
      "F Beta Score (Beta=10) 0.00748497446957\n",
      " \n",
      "Target percentage 0.8\n",
      "y.shape =  743 y.mean() =  0.7994616419919246\n",
      "ntree =  500\n",
      "F Beta Score (Beta=10) 0.00741924588684\n",
      " \n",
      "Target percentage 0.9\n",
      "y.shape =  655 y.mean() =  0.9068702290076336\n",
      "ntree =  100\n",
      "F Beta Score (Beta=10) 0.00627813618431\n",
      " \n",
      "Target percentage 0.9\n",
      "y.shape =  655 y.mean() =  0.9068702290076336\n",
      "ntree =  200\n",
      "F Beta Score (Beta=10) 0.00624011965685\n",
      " \n",
      "Target percentage 0.9\n",
      "y.shape =  655 y.mean() =  0.9068702290076336\n",
      "ntree =  500\n",
      "F Beta Score (Beta=10) 0.00623170570417\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for target_percentage in [0.2,0.4,0.6,0.8,0.9]:\n",
    "    for ntree in [100,200,500]:\n",
    "        X_u, y_u = UnderSampling(X_train, y_train, target_percentage, 666)\n",
    "        print('Target percentage', target_percentage)\n",
    "        print('y.shape = ',y_u.shape[0], 'y.mean() = ', y_u.mean())\n",
    "        print('ntree = ',ntree)\n",
    "        rfclas = RandomForestClassifier(n_estimators=ntree, random_state=666, n_jobs=-1)\n",
    "        rfclas.fit(X_u,y_u)\n",
    "        y_pred_class_RF = rfclas.predict(X_test)\n",
    "        print('F Beta Score (Beta=10)',metrics.fbeta_score(y_pred_class_RF,y_test,beta=10))\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el anterior ejercicio se puede observar que se hace la comparación de modelos Random Forest variando los parámetros de cantidad de árboles y utilizando Under Sampling se concluye que el valor del Target percentage que optimiza el F Beta Score es 0.2 y 500 árboles. A medida que el Target percentage aumenta, el F Beta Score disminuye, sin embargo el comportamiento de los árboles es un poco impreciso, ya que para Target percentage = 0.2 a mayor cantidad de árboles, el F Beta mejora, sin embargo, para un Target percentage = 0.9 a mayor cantidad de árboles el F Beta Score empeora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
